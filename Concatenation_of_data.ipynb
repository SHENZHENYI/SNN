{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concatenation of data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwYf8daTHv0",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQR4_QtoTKhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "158d4d5d-9c7e-46c0-d20b-6f5dbb5ef7af"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "with zipfile.ZipFile('NMNISTsmall.zip') as zip_file:\n",
        "    for member in zip_file.namelist():\n",
        "        if not os.path.exists('./' + member):\n",
        "            zip_file.extract(member, './')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport zipfile\\nimport os\\nwith zipfile.ZipFile('NMNISTsmall.zip') as zip_file:\\n    for member in zip_file.namelist():\\n        if not os.path.exists('./' + member):\\n            zip_file.extract(member, './')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgT6e1ULTAGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import spikeFileIO as io\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noCmUW3kTGho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "916a5618-5859-4b05-83d0-5b984543e38d"
      },
      "source": [
        "#lets collect addresses of training and test data\n",
        "def load(fname):\n",
        "    f = open(fname,'r')\n",
        "\n",
        "    data = []\n",
        "    for line in f.readlines():\n",
        "        data.append(line.replace('\\n','').split(' '))\n",
        "\n",
        "    f.close()\n",
        "\n",
        "    return data\n",
        "\n",
        "path = 'NMNISTsmall/'\n",
        "#train data\n",
        "training_files = load('NMNISTsmall/train1K.txt')\n",
        "training_files = training_files[1:]\n",
        "\n",
        "training_addrs = []\n",
        "training_labels = []\n",
        "for i in range (len(training_files)):\n",
        "  training_addrs.append(path+training_files[i][0][:-2]+'.bs2')\n",
        "  training_labels.append(training_files[i][0][-1])\n",
        "\n",
        "#test data\n",
        "test_files = load('NMNISTsmall/test100.txt')\n",
        "test_files = test_files[1:]\n",
        "\n",
        "test_addrs = []\n",
        "test_labels = []\n",
        "for i in range (len(test_files)):\n",
        "  test_addrs.append(path+test_files[i][0][:-2]+'.bs2')\n",
        "  test_labels.append(test_files[i][0][-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#lets collect addresses of training and test data\\ndef load(fname):\\n    f = open(fname,'r')\\n\\n    data = []\\n    for line in f.readlines():\\n        data.append(line.replace('\\n','').split(' '))\\n\\n    f.close()\\n\\n    return data\\n\\npath = 'NMNISTsmall/'\\n#train data\\ntraining_files = load('NMNISTsmall/train1K.txt')\\ntraining_files = training_files[1:]\\n\\ntraining_addrs = []\\ntraining_labels = []\\nfor i in range (len(training_files)):\\n  training_addrs.append(path+training_files[i][0][:-2]+'.bs2')\\n  training_labels.append(training_files[i][0][-1])\\n\\n#test data\\ntest_files = load('NMNISTsmall/test100.txt')\\ntest_files = test_files[1:]\\n\\ntest_addrs = []\\ntest_labels = []\\nfor i in range (len(test_files)):\\n  test_addrs.append(path+test_files[i][0][:-2]+'.bs2')\\n  test_labels.append(test_files[i][0][-1])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1EZ_3_oVVO7",
        "colab_type": "text"
      },
      "source": [
        "Instead of retaining only the first earliest spikes, we can retain more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFoK64m9VT5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xyp21dim_onlyfirstspikepreserved(TD):\n",
        "  TD_temporal = torch.ones((34,34,2))*2.8 #assumed that 2.8 is a mask number, identified as no-spiking time. 2.8 is due to historical reason\n",
        "  t_max = TD.t[-1]\n",
        "  for i in range(TD.x.shape[0]):\n",
        "    if TD_temporal[TD.x[i], TD.y[i], TD.p[i]] == 2.8:\n",
        "      TD_temporal[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max #normalisation\n",
        "  return TD_temporal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxU-Q8dF8qGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xyp21dim_fewmorespikes(TD):\n",
        "  TD_temporal_1 = torch.ones((34,34,2))*2.8 #assumed that 2.8 is a mask number, identified as no-spiking time. 2.8 is due to historical reason\n",
        "  TD_temporal_2 = torch.ones((34,34,2))*2.8\n",
        "  TD_temporal_3 = torch.ones((34,34,2))*2.8\n",
        "  TD_temporal_4 = torch.ones((34,34,2))*2.8\n",
        "  TD_temporal_5 = torch.ones((34,34,2))*2.8\n",
        "  TD_temporal_6 = torch.ones((34,34,2))*2.8\n",
        "\n",
        "  pixel_occur_first_time = []\n",
        "  pixel_occur_second_time = []\n",
        "  pixel_occur_third_time = []\n",
        "  pixel_occur_forth_time =[]\n",
        "  pixel_occur_fifth_time =[]\n",
        "  pixel_occur_sixth_time =[]\n",
        "\n",
        "  t_max = TD.t[-1]\n",
        "\n",
        "  for i in range(TD.x.shape[0]):\n",
        "    if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_first_time:\n",
        "      TD_temporal_1[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "      pixel_occur_first_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "    else:\n",
        "      if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_second_time:\n",
        "        TD_temporal_2[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "        pixel_occur_second_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "      else:\n",
        "        if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_third_time:\n",
        "          TD_temporal_3[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "          pixel_occur_third_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "        else:\n",
        "          if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_forth_time:\n",
        "            TD_temporal_4[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "            pixel_occur_forth_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "          else:\n",
        "            if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_fifth_time:\n",
        "              TD_temporal_5[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "              pixel_occur_fifth_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "            else:\n",
        "              if [TD.x[i], TD.y[i], TD.p[i]] not in pixel_occur_sixth_time:\n",
        "                TD_temporal_6[TD.x[i], TD.y[i], TD.p[i]] = TD.t[i]/t_max\n",
        "                pixel_occur_sixth_time.append([TD.x[i], TD.y[i], TD.p[i]])\n",
        "  return TD_temporal_1, TD_temporal_2,TD_temporal_3, TD_temporal_4, TD_temporal_5, TD_temporal_6, pixel_occur_first_time, pixel_occur_second_time,pixel_occur_third_time,pixel_occur_forth_time, pixel_occur_fifth_time,pixel_occur_sixth_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oX-9-VXg-AG",
        "colab_type": "text"
      },
      "source": [
        "change the mode to have different feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Of53-gTOU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense_data_generator(X, y, batch_size, samplingTime=1, samplingLength=300, shuffle=True, device = 'cuda', dtype=torch.float, mode = 'concatenation6'):\n",
        "    \"\"\" This generator takes training data's address and generates spiking network input as dense tensors. \n",
        "\n",
        "    Args:\n",
        "        X: The data ( 'data/userx_lighting_conditions/y.npy' )\n",
        "        y: The labels\n",
        "        batch_size: batch size\n",
        "        samplingTime: period of sampling; default is 1ms\n",
        "        samplingLength: in SLAYER training as well as testing, only the first 1.5 s out of â‰ˆ 6 s of action video for each clas\n",
        "    \"\"\" \n",
        "    nTimeBins = int(samplingLength/samplingTime)\n",
        "    labels_ = np.array(y,dtype=np.int)\n",
        "    number_of_batches = len(X)//batch_size\n",
        "    sample_index = np.arange(len(X))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(sample_index)\n",
        "\n",
        "    total_batch_count = 0\n",
        "    counter = 0\n",
        "    while counter<number_of_batches:\n",
        "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
        "        #initialise X_batch\n",
        "        if mode == 'normal': #the input signal is only the first spiking time\n",
        "          X_batch = torch.empty((batch_size,2*34*34),dtype=dtype)\n",
        "        elif mode == 'concatenation': #the input signal is the first spiking time concatenated with the second spiking time\n",
        "          X_batch = torch.empty((batch_size,2*34*34*2),dtype=dtype)\n",
        "        elif mode == 'concatenation6': #the input signal is the first spiking time concatenated with the second spiking time\n",
        "          X_batch = torch.empty((batch_size,2*34*34*6),dtype=dtype)   \n",
        "        #assign values to X_batch\n",
        "        for bc,i in enumerate(batch_index):\n",
        "            TD = io.read2Dspikes(X[i])\n",
        "            if mode == 'normal':\n",
        "              X_batch_temp = xyp21dim_onlyfirstspikepreserved(TD)\n",
        "              #X_batch_temp,X_batch_temp_second,_,_ = xyp21dim_first2spikepreserved_test(TD)\n",
        "              X_batch[bc] = X_batch_temp.view((-1))\n",
        "\n",
        "            elif mode == 'concatenation':\n",
        "              X_batch_temp_first,X_batch_temp_second,_,_ = xyp21dim_first2spikepreserved_test(TD)\n",
        "              #X_batch_temp_second = downsampling4(X_batch_temp_second, mode = 'average')\n",
        "              X_batch[bc] = torch.cat((X_batch_temp_first.view((-1)), X_batch_temp_second.view((-1))), 0)\n",
        "\n",
        "            elif mode == 'concatenation6':\n",
        "              TD_temporal_1, TD_temporal_2,TD_temporal_3, TD_temporal_4, TD_temporal_5, TD_temporal_6, _,_,_,_,_,_ = xyp21dim_fewmorespikes(TD)              #X_batch_temp_second = downsampling4(X_batch_temp_second, mode = 'average')\n",
        "              X_batch[bc] = torch.cat((TD_temporal_1.view((-1)), TD_temporal_2.view((-1)),TD_temporal_3.view((-1)), TD_temporal_4.view((-1)),TD_temporal_5.view((-1)), TD_temporal_6.view((-1))), 0)\n",
        "\n",
        "\n",
        "            #flatten dimensions and save in X_batch\n",
        "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
        "        yield [X_batch.to(device=device), y_batch.to(device=device)] \n",
        "        counter+=1    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5nTmcjaqFPJ",
        "colab_type": "text"
      },
      "source": [
        "# Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCZfWyT_bN_6",
        "colab_type": "text"
      },
      "source": [
        "Kernel generates spiking time of a neuron given some input spike time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnxjGL5ZGNpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alpha_kernel_response_temporal_v2(input_time, weights, tau = 1, thre = 1): #faster implementation\n",
        "  #argument: input_time shape = (n_batch x n_input);  weights shape = (n_input x n_output)\n",
        "  #alpha_kernel_response is t*e^(tau*t); the increment of this kernel is (1+t*tau)*exp(tau*t)\n",
        "  n_batch = input_time.shape[0]\n",
        "  n_input = input_time.shape[1]\n",
        "  n_output = weights.shape[1]\n",
        "  precision = 100.0\n",
        "  index = torch.where(input_time != 2.8)\n",
        "  t_max = torch.max(input_time[index]) + 4.0 #4 is the designed kernel length\n",
        "  n_max = precision*t_max\n",
        "\n",
        "  v_accu = torch.zeros((n_batch, n_output), device = input_time.device)\n",
        "  spike_time = torch.zeros_like(v_accu)\n",
        "  spike_time_mem = torch.ones_like(v_accu)\n",
        "  for t in range(int(n_max)):\n",
        "    t_clamp = torch.clamp(t/precision -input_time, 0, t_max)\n",
        "    invalid_incr = (t_clamp==0)\n",
        "    exptau = torch.exp(-tau*t_clamp)\n",
        "    v_incr = exptau*(1-tau*t_clamp)/precision + 0.5/(precision**2) *exptau*tau*(2+tau)  #unweighted dv/dt\n",
        "    v_incr[invalid_incr] = 0\n",
        "    v_incr = torch.mm(v_incr, weights) #dv/dt * delta_t\n",
        "    v_accu += v_incr #update the membrane potential at time instance t\n",
        "    index = (v_accu>thre) & (spike_time_mem == 1) #output index to update the earilest spiking time\n",
        "    spike_time[index] = t/precision\n",
        "    spike_time_mem[index] = 0 #mark the updated output index such that it will not be updated again\n",
        "  \n",
        "  index_nospike = (spike_time == 0)\n",
        "  spike_time[index_nospike] = 2.8 #an arbirary number that identifies no-spiking neuron\n",
        "  \n",
        "  return spike_time.to(input_time.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_StECwi5qXf0",
        "colab_type": "text"
      },
      "source": [
        "# Network Configuratoin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Q514pfXcnS",
        "colab_type": "text"
      },
      "source": [
        "Here we configure a SNN with input layer of a size 2x34x34, a hidden layer of a size 100, and an output layer of a size 10. Moreover, both the input layer and the hidden layer have one bias to prevent neuron from not spiking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZVG4RZqpht",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUAfoCdX6eb",
        "colab_type": "text"
      },
      "source": [
        "helper function that solves W-Lambert function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N5rceeTKZJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/google/ihmehimmeli/blob/master/tempcoding/lambertw.cc\n",
        "def LambertW0InitialGuess_vec(x):\n",
        "  kNearBranchCutoff = -0.3235\n",
        "  kE = 2.718281828459045\n",
        "  x_copy = x.clone()\n",
        "\n",
        "  # Sqrt approximation near branch cutoff.\n",
        "  index1 = (x < kNearBranchCutoff)\n",
        "  x_copy[index1] = -1.0+torch.sqrt(2.0*(1+kE*x[index1]))\n",
        "\n",
        "  # Taylor series between [-1/e and 1/e].\n",
        "  index2 = (x > kNearBranchCutoff) & (x < -kNearBranchCutoff)\n",
        "  x_copy[index2] = x[index2] * (1 + x[index2] * (-1 + x[index2] * (3.0 / 2.0 - 8.0 / 3.0 * x[index2])))\n",
        "\n",
        "  #Series of piecewise linear approximation\n",
        "  index3 = (x > -kNearBranchCutoff) & (x < 0.6)\n",
        "  x_copy[index3] =  0.23675531078855933 + (x[index3] - 0.3) * 0.5493610866617109\n",
        "  \n",
        "  index4 = (x > 0.6) & (x < 0.8999999999999999)\n",
        "  x_copy[index4] = 0.4015636367870726 + (x[index4] - 0.6) * 0.4275644294878729\n",
        "\n",
        "  index5 = (x > 0.8999999999999999) & (x < 1.2)\n",
        "  x_copy[index5] = 0.5298329656334344 + (x[index5] - 0.8999999999999999) * 0.3524368357714513\n",
        "\n",
        "  index6 = (x > 1.2) & (x < 1.5)\n",
        "  x_copy[index6] = 0.6355640163648698 + (x[index6] - 1.2) * 0.30099113800452154\n",
        "\n",
        "  index7 = (x > 1.5) & (x < 1.8)\n",
        "  x_copy[index7] = 0.7258613577662263 + (x[index7] - 1.5) * 0.2633490154764343\n",
        "  \n",
        "  index8 = (x > 1.8) & (x < 2.0999999999999996)\n",
        "  x_copy[index8] = 0.8048660624091566 + (x[index8] - 1.8) * 0.2345089875713013;\n",
        "  \n",
        "  index9 = (x > 2.0999999999999996) & (x < 2.4)\n",
        "  x_copy[index9] =  0.8752187586805469 + (x[index9] - 2.0999999999999996) * 0.2116494532726034\n",
        "\n",
        "  index10 = (x > 2.4) & (x < 2.6999999999999997)\n",
        "  x_copy[index10] = 0.938713594662328 + (x[index10] - 2.4) * 0.19305046534383152\n",
        "\n",
        "  index11 = (x > 2.6999999999999997) & (x < 2.9999999999999996)\n",
        "  x_copy[index11] = 0.9966287342654774 + (x[index11] - 2.6999999999999997) * 0.17760053566187495\n",
        "  \n",
        "  #asymptotic approxiamtion\n",
        "  index12 = ~(index1 + index2 + index3 + index4 + index5 + index6 +index7 +index8 +index9 +index10 + index11)\n",
        "  l = torch.log(x[index12])\n",
        "  ll = torch.log(l)\n",
        "  x_copy[index12] = l - ll + ll/l\n",
        "  return x_copy\n",
        "\n",
        "def LambertW0_vec(x):\n",
        "  x_copy = x.clone()\n",
        "  kReciprocalE = 0.36787944117\n",
        "  kDesiredAbsoluteDifference = 1e-3\n",
        "  kNumMaxIters = 10\n",
        "\n",
        "  index1 =  (x < -kReciprocalE)\n",
        "  x_copy[index1] = 0\n",
        "  #return x, False\n",
        "\n",
        "  index2 = (x == 0.0)\n",
        "  x_copy[index2] = 0\n",
        "\n",
        "  index3 = (x == -kReciprocalE)\n",
        "  x_copy[index3] = -1 \n",
        "\n",
        "  index4 = ~(index1 + index2 + index3)\n",
        "\n",
        "  #current guess\n",
        "  w_n = LambertW0InitialGuess_vec(x[index4])\n",
        "  have_convergence = False\n",
        "\n",
        "  #fritsch iteration\n",
        "  for i in range(1):\n",
        "    z_n = torch.log(x[index4] / w_n) - w_n\n",
        "    q_n = 2.0 * (1.0 + w_n) * (1.0 + w_n + 2.0 / 3.0 * z_n)\n",
        "    e_n = (z_n / (1.0 + w_n)) * ((q_n - z_n) / (q_n - 2.0 * z_n))\n",
        "    w_n = w_n * (1.0 + e_n)\n",
        "    #Done this way as the log is the expensive part above.\n",
        "    #if (torch.abs(z_n) < kDesiredAbsoluteDifference):\n",
        "\n",
        "  x_copy[index4] = w_n\n",
        "  return x_copy\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsrbscrmYSLk",
        "colab_type": "text"
      },
      "source": [
        "# Forward and backward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBeu4hrGKU6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNN_process_v3(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weight, bias_time, bias_weight):\n",
        "        \"\"\"\n",
        "        Argument: input is input spike time of dimension (n_output)\n",
        "                  weight is of dimension (n_input, n_output)\n",
        "                  bias_time is of dimension (n_bias)\n",
        "                  bias_weight is of dimension (n_bias, n_output)\n",
        "        \"\"\"\n",
        "        #####firstly, we combine the bias and inputs, and their weights#####\n",
        "        batch_size = input.shape[0]\n",
        "        n_bias = bias_time.shape[0]\n",
        "        bias_time_broadcasted = bias_time.view(1,n_bias).repeat(batch_size,1)\n",
        "        x_n_bias = torch.cat((input, bias_time_broadcasted),-1)\n",
        "\n",
        "        w_n_bias = torch.cat((weight,bias_weight),0)\n",
        "\n",
        "        #####membrane dynamics begin here###################################\n",
        "        tau =  2#0.181769\n",
        "        theta = 0.5 #1.16732\n",
        "        not_spike_time = 2.8 #if the neuron does not spike, the spike time is assigned to 2.8 sec. It is a potential problem\n",
        "        nb_outputs = w_n_bias.shape[1]\n",
        "\n",
        "        spk = alpha_kernel_response_temporal_v2(x_n_bias, w_n_bias, tau = tau, thre = theta)\n",
        "        ctx.intermediate_results = x_n_bias, w_n_bias, spk, n_bias\n",
        "\n",
        "        return spk\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        x_n_bias, w1_n_bias, spk, n_bias = ctx.intermediate_results\n",
        "        tau = 2 #0.181769\n",
        "        theta = 0.5 #1.16732\n",
        "        input = x_n_bias\n",
        "        batch_size = x_n_bias.shape[0]\n",
        "        nb_inputs = w1_n_bias.shape[0]\n",
        "        nb_outputs = w1_n_bias.shape[1]\n",
        "\n",
        "        #t0 = time.time()\n",
        "        #compute ingredients of gradients \n",
        "        AI = torch.zeros_like(spk).to(input.device)  #initialisation\n",
        "        BI = torch.zeros_like(spk).to(input.device)\n",
        "        t_out = torch.zeros_like(spk).to(input.device)\n",
        "        WI = torch.zeros_like(spk).to(input.device)\n",
        "        grad_input = torch.zeros((batch_size, nb_inputs, nb_outputs)).to(input.device)\n",
        "        grad_weight = torch.zeros((batch_size, nb_inputs, nb_outputs)).to(input.device)\n",
        "\n",
        "        #extend matrices to a common shape\n",
        "        x_n_bias_modified = x_n_bias.unsqueeze(2).repeat(1,1,nb_outputs)\n",
        "        grad_output_modified = grad_output.unsqueeze(1).repeat(1,nb_inputs,1)\n",
        "        w1_n_bias_repeated = w1_n_bias.unsqueeze(0).repeat(batch_size,1,1)\n",
        "\n",
        "        #find the index for valid inputs \n",
        "        spk_modified = spk.unsqueeze(1).repeat(1,nb_inputs,1)\n",
        "        valid_index = x_n_bias_modified < spk_modified\n",
        "\n",
        "        #print(valid_index)\n",
        "        AI = torch.sum(torch.exp(x_n_bias_modified*tau)*w1_n_bias_repeated*valid_index, 1).to(x_n_bias.device)\n",
        "        BI = torch.sum(torch.exp(x_n_bias_modified*tau)*x_n_bias_modified*w1_n_bias_repeated*valid_index, 1).to(x_n_bias.device)\n",
        "        #t1 = time.time()\n",
        "        #print('AI and BI', t1-t0)\n",
        "        exploding_WI_idx_batch = []\n",
        "        exploding_WI_idx_out = []\n",
        "\n",
        "        WI_intermediate = -tau*theta/AI * torch.exp(tau*BI/AI)\n",
        "        #print('WI_intermediate',WI_intermediate)\n",
        "        valid_WI_index = WI_intermediate != float('inf')\n",
        "        WI[valid_WI_index] = LambertW0_vec(WI_intermediate[valid_WI_index])\n",
        "        spk[~valid_WI_index] = 2.8\n",
        "\n",
        "        spk_modified = spk.unsqueeze(1).repeat(1,nb_inputs,1) #update spk_modified, as spk changes\n",
        "       \n",
        "\n",
        "        #extend matrices to a common shape\n",
        "        AI_modified = AI.unsqueeze(1).repeat(1,nb_inputs,1)\n",
        "        BI_modified = BI.unsqueeze(1).repeat(1,nb_inputs,1)\n",
        "        WI_modified = WI.unsqueeze(1).repeat(1,nb_inputs,1)\n",
        "\n",
        "        valid_weights = w1_n_bias_repeated*valid_index #only inputs contributed to the spike generation are recognised as valid inputs\n",
        "\n",
        "        dtout_dtin = grad_output_modified*valid_weights*torch.exp(x_n_bias_modified)*(x_n_bias_modified - BI_modified/AI_modified + WI_modified + 1)/(AI_modified*(1+WI_modified))\n",
        "        #no spk penalty\n",
        "        no_spk_idx = torch.where(spk_modified == 2.8)\n",
        "        dtout_dtin[no_spk_idx] = 0\n",
        "        grad_input = torch.sum(dtout_dtin,2)\n",
        "\n",
        "        dtout_dw = grad_output_modified*valid_index*torch.exp(x_n_bias_modified)*(x_n_bias_modified - BI_modified/AI_modified + WI_modified)/(AI_modified*(1+WI_modified))\n",
        "        dtout_dw[no_spk_idx] = -1\n",
        "        grad_weight = torch.sum(dtout_dw,0)\n",
        "\n",
        "        ##clip at 100\n",
        "        torch.clamp(grad_weight, min=-100, max=100)\n",
        "        torch.clamp(grad_input, min=-100, max=100)\n",
        "\n",
        "        #solve nan values\n",
        "        index_nan_t = torch.where(grad_input != grad_input)\n",
        "        grad_input[index_nan_t] = 0\n",
        "        index_nan_w = torch.where(grad_weight != grad_weight)\n",
        "        grad_weight[index_nan_w] = 0        \n",
        "        \n",
        "        index_nan_t = torch.where(grad_input == float('inf'))\n",
        "        grad_input[index_nan_t] = 100\n",
        "        index_nan_w = torch.where(grad_weight == float('inf'))\n",
        "        grad_weight[index_nan_w] = 100  \n",
        "\n",
        "        index_nan_t = torch.where(grad_input == float('-inf'))\n",
        "        grad_input[index_nan_t] = -100\n",
        "        index_nan_w = torch.where(grad_weight == float('-inf'))\n",
        "        grad_weight[index_nan_w] = -100   \n",
        "\n",
        "        return grad_input[:,:nb_inputs-n_bias], grad_weight[:nb_inputs-n_bias,:], grad_input[:,nb_inputs-n_bias:].view(batch_size,n_bias), grad_weight[nb_inputs-n_bias:,:].view(n_bias,nb_outputs) #I ignored the grad for the bias\n",
        "\n",
        "snn_process_v3 = SNN_process_v3.apply"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeq_GsruYm_g",
        "colab_type": "text"
      },
      "source": [
        "# Store the data in a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2os--Upf3tvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d40e956-ba42-4fc2-e617-c2dabec46de1"
      },
      "source": [
        "#load training data for training\n",
        "import time\n",
        "batch_size = 5\n",
        "x_batch =[]\n",
        "y_batch =[]\n",
        "t0 = time.time()\n",
        "for x_local, y_local in dense_data_generator(training_addrs, training_labels, batch_size, shuffle=True):\n",
        "  x_batch.append(x_local)\n",
        "  y_batch.append(y_local)\n",
        "t1 = time.time()\n",
        "print(t1-t0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#load training data for training\\nimport time\\nbatch_size = 5\\nx_batch =[]\\ny_batch =[]\\nt0 = time.time()\\nfor x_local, y_local in dense_data_generator(training_addrs, training_labels, batch_size, shuffle=True):\\n  x_batch.append(x_local)\\n  y_batch.append(y_local)\\nt1 = time.time()\\nprint(t1-t0)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMhDf_dy4mYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8bb5291d-45bf-40b2-be50-374174a88df9"
      },
      "source": [
        "#load trainig data for accuracy\n",
        "for x_test, y_test in dense_data_generator(test_addrs, test_labels, len(test_addrs), shuffle=False):\n",
        "  1 == 1\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#load trainig data for accuracy\\nfor x_test, y_test in dense_data_generator(test_addrs, test_labels, len(test_addrs), shuffle=False):\\n  1 == 1\\nprint(x_test.shape)\\nprint(y_test.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfQ5Cl5chUUK",
        "colab_type": "text"
      },
      "source": [
        "If the RAM is limited, we can store the data in the disk, and load from there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHXXNA1ShP-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def training_data_generator_20(batch_number = 50, batch_size=20, device = 'cuda', dtype=torch.float):\n",
        "    counter = 0\n",
        "    while counter<batch_number:\n",
        "        [x_batch, y_batch] = torch.load('drive/My Drive/digit_6spikes/digit_training_data_bs20_6spikes_{:02d}.pt'.format(counter))\n",
        "        yield [x_batch[:,:2*34*34*2].to(device=device), y_batch.to(device=device)] \n",
        "        counter+=1\n",
        "\n",
        "def test_data_generator_20(batch_number = 5, batch_size=20, device = 'cuda', dtype=torch.float):\n",
        "    counter = 0\n",
        "    while counter<batch_number:\n",
        "        [x_batch, y_batch] = torch.load('drive/My Drive/digit_6spikes/digit_test_data_bs20_6spikes_{:02d}.pt'.format(counter))\n",
        "        yield [x_batch[:,:2*34*34*2].to(device=device), y_batch.to(device=device)] \n",
        "        counter+=1\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5RhokqyYuaW",
        "colab_type": "text"
      },
      "source": [
        "# Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-imZaZmOf28N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[w1,w2, bias1_weight, bias2_weight, bias1_time, bias2_time] = torch.load('params_baseline300.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62FW9Mdeure8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_classification_accuracy(x_data, y_data):\n",
        "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
        "    accs = []\n",
        "    spk_hidden = snn_process_v3(x_data, torch.cat((w1,w1),0), bias1_time, bias1_weight)\n",
        "    spk_out = snn_process_v3(spk_hidden, w2, bias2_time, bias2_weight)\n",
        "    pred = torch.argmin(spk_out,1)\n",
        "    acc = np.mean((y_data==pred).detach().cpu().numpy())\n",
        "    accs.append(acc)\n",
        "    return np.mean(accs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNULZU2lbTH-",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tca7YtDCqobA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b94ffe4a-1da1-4b3a-a83c-bddfcbb020b5"
      },
      "source": [
        "nb_inputs  = 2*34*34*2\n",
        "nb_hidden  = 300\n",
        "nb_outputs = 10\n",
        "#we assume there is only 1 batch now\n",
        "\n",
        "#weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
        "\n",
        "dtype=torch.float\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")     \n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "#initialisation\n",
        "weight_scale = np.sqrt(2)\n",
        "\n",
        "nb_bias1 = 10\n",
        "nb_bias2 = 10\n",
        "\n",
        "\n",
        "w1 = torch.empty((int(nb_inputs/2), nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w1, mean=-0.275419*weight_scale/np.sqrt(nb_inputs+nb_hidden+nb_bias1), std=weight_scale/np.sqrt(nb_inputs+nb_hidden+nb_bias1)) #the mean is brought up to 1.5 to force neurons to spike initially\n",
        "\n",
        "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w2, mean=-0.275419*weight_scale/np.sqrt(nb_inputs+nb_hidden+nb_bias2), std=weight_scale/np.sqrt(nb_hidden+nb_outputs+nb_bias2))\n",
        "\n",
        "bias1_time = torch.empty((nb_bias1),  device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.uniform_(bias1_time, a=0.0, b=1.0)\n",
        "bias1_weight = torch.empty((nb_bias1, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(bias1_weight, mean=7.83912*weight_scale/np.sqrt(nb_inputs+nb_bias1+nb_hidden), std=weight_scale/np.sqrt(nb_inputs+nb_bias1+nb_hidden))\n",
        "#torch.nn.init.uniform_(bias1_weight, a=1.0, b=1.0)\n",
        "\n",
        "\n",
        "bias2_time = torch.empty((nb_bias2),  device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.uniform_(bias2_time, a=0.0, b=1.0)\n",
        "bias2_weight = torch.empty((nb_bias2, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(bias2_weight, mean=7.83912*weight_scale/np.sqrt(nb_outputs+nb_bias2+nb_hidden), std=weight_scale/np.sqrt(nb_outputs+nb_bias2+nb_hidden))\n",
        "#torch.nn.init.uniform_(bias2_weight, a=1.0, b=1.0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5783, 0.5680, 0.5957, 0.6046, 0.5714, 0.6079, 0.6341, 0.6473, 0.7289,\n",
              "         0.6496],\n",
              "        [0.6293, 0.6639, 0.5421, 0.6772, 0.5713, 0.7271, 0.5755, 0.7280, 0.4283,\n",
              "         0.6720],\n",
              "        [0.5116, 0.6253, 0.5048, 0.5881, 0.6289, 0.7419, 0.6511, 0.6643, 0.5604,\n",
              "         0.6214],\n",
              "        [0.4492, 0.6639, 0.7306, 0.5801, 0.7676, 0.5942, 0.5643, 0.6592, 0.6418,\n",
              "         0.6190],\n",
              "        [0.7869, 0.5545, 0.5983, 0.6805, 0.5832, 0.5907, 0.5662, 0.4872, 0.7432,\n",
              "         0.6460],\n",
              "        [0.7115, 0.6319, 0.4918, 0.6156, 0.6969, 0.6360, 0.7009, 0.6715, 0.6126,\n",
              "         0.5908],\n",
              "        [0.6045, 0.6240, 0.7109, 0.5788, 0.5819, 0.6132, 0.4698, 0.6295, 0.6362,\n",
              "         0.6480],\n",
              "        [0.6074, 0.5554, 0.6071, 0.5647, 0.5152, 0.6309, 0.5130, 0.5369, 0.6650,\n",
              "         0.5872],\n",
              "        [0.6673, 0.5741, 0.5732, 0.6222, 0.5313, 0.6970, 0.5635, 0.5945, 0.6246,\n",
              "         0.5745],\n",
              "        [0.7320, 0.6229, 0.7566, 0.6198, 0.6161, 0.6717, 0.7276, 0.5397, 0.5090,\n",
              "         0.5889]], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qibiy0NViS9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#[w1,w12, w2, bias1_weight, bias2_weight, bias1_time, bias2_time] = torch.load('params_baseline300.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38iWObKTB7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "paramw = [w1, w12]\n",
        "params = [ w2, bias1_weight, bias2_weight]\n",
        "params_time = [bias1_time, bias2_time]\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "m = nn.L1Loss()\n",
        "\n",
        "#n_batch = int(1000/batch_size)\n",
        "lr = 2e-3\n",
        "lr_pulse = 6e-2\n",
        "\n",
        "loss_list = []\n",
        "loss_hist = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "train_accuracy= 0\n",
        "pred_hist = torch.zeros(1000,3,2)\n",
        "\n",
        "for e in range(100):\n",
        "    optimizerw = torch.optim.Adam(paramw, lr=lr, betas=(0.9,0.999))\n",
        "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
        "    optimizer_bias_time = torch.optim.Adam(params_time, lr=lr_pulse, betas=(0.9,0.999))\n",
        "\n",
        "    #####run snn begins###\n",
        "    t0 = time.time()\n",
        "    #for x_local, y_local in dense_data_generator(training_addrs, training_labels, batch_size, shuffle=False):\n",
        "    for x_local, y_local in training_data_generator_20(batch_number = 50): #here I load the data from the disk\n",
        "      spk_hidden = snn_process_v3(x_local, torch.cat((w1,w1),0), bias1_time, bias1_weight) #we concatenate two w1s to construct a new w1\n",
        "      spk_out = snn_process_v3(spk_hidden, w2, bias2_time, bias2_weight)\n",
        "      #####run snn ends#####\n",
        "\n",
        "      loss = loss_fn(-spk_out, y_local)\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "      optimizerw.zero_grad()\n",
        "      optimizer.zero_grad()\n",
        "      optimizer_bias_time.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizerw.step()\n",
        "      optimizer.step()\n",
        "      optimizer_bias_time.step()\n",
        "\n",
        "    loss_list_t=torch.FloatTensor(loss_list) \n",
        "    loss_hist.append(torch.mean(loss_list_t))\n",
        "\n",
        "    #compute accuracies\n",
        "    acc_list = []\n",
        "    for x_local, y_local in training_data_generator_20(batch_number = 50):\n",
        "      acc = compute_classification_accuracy(x_local,y_local)\n",
        "      acc_list.append(acc)\n",
        "    train_accuracy = np.mean(acc_list)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    acc_list = []\n",
        "    for x_local, y_local in test_data_generator_20(batch_number = 5):\n",
        "        acc = compute_classification_accuracy(x_local,y_local)\n",
        "        acc_list.append(acc)\n",
        "    test_accuracy = np.mean(acc_list)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "\n",
        "    t1 = time.time()\n",
        "    print('epoch number: ', e, 'loss is ', loss_hist[e].item(), 'train accu is', train_accuracy, 'test accu is', test_accuracy, 'lr', lr, 'time=', t1-t0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfYh4hh2h7Lv",
        "colab_type": "text"
      },
      "source": [
        "save all the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy0u5-SfW7x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save([w1 ,w12,w2, bias1_weight, bias2_weight, bias1_time, bias2_time], 'params_baseline300.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-vICdPbh4e5",
        "colab_type": "text"
      },
      "source": [
        "plot the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq3kMskLyttW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot (train_accuracies,  label='train')\n",
        "plt.plot (test_accuracies, label='test')\n",
        "plt.legend()\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Accuracy')\n",
        "#plt.savefig('accuracy.eps')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFoEFGudh1w3",
        "colab_type": "text"
      },
      "source": [
        "plot the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IcugE88yI-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cf_total = np.zeros((10,10))\n",
        "for i in range (10):\n",
        "  spk_hidden = snn_process_v3(x_batch[i], w1, bias1_time, bias1_weight)\n",
        "  spk_out = snn_process_v3(spk_hidden, w2, bias2_time, bias2_weight)\n",
        "  y_pred = torch.argmin(spk_out,1)\n",
        "  cf = confusion_matrix(y_batch[i].detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
        "  cf_total += cf\n",
        "print(cf_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Q_5th_yJuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_total_row = np.sum(cf_total, 1)\n",
        "cf_total_row_expanded = np.zeros((10,10))\n",
        "for i in range(10):\n",
        "  cf_total_row_expanded[:,i] = cf_total_row\n",
        "cf_norm = cf_total/cf_total_row_expanded\n",
        "cf_norm = (100*cf_norm).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qJMFWRe1B4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import seaborn as sn\n",
        "\n",
        "sn.heatmap(cf_norm, annot=True)\n",
        "plt.ylabel('true label')\n",
        "plt.xlabel('predicted label')\n",
        "plt.savefig('snn_baseline_cf_300tmax_v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHTk-rBG1Ich",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}